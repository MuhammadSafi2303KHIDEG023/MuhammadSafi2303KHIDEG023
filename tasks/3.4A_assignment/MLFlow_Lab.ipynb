{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Muhammad Safi (2303.KHI.DEG.023)\n",
    "\n",
    "Assignment Partner: Huzaifa Ali (2303.KHI.DEG.016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/muhammadsafi/Desktop/assignment_repo/tasks/mlops-assignment/bin/python\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import sys; print(sys.executable)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up MLFlow Tracking Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "\n",
    "mlflow server --host 0.0.0.0 \\\n",
    "    --port 5000 \\\n",
    "    --backend-store-uri sqlite:///mlflow.db \\\n",
    "    --default-artifact-root ./mlruns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: basic_mlflow\n",
      "\n",
      "# this file is used to configure Python package dependencies.\n",
      "# it uses Anaconda, but it can be also alternatively configured to use pip.\n",
      "conda_env: conda.yaml\n",
      "\n",
      "# entry points can be ran using `mlflow run <project_name> -e <entry_point_name>\n",
      "entry_points:\n",
      "  # download_data:\n",
      "  #   # you can run any command using MLFlow\n",
      "  #   command: \"bash download_data.sh\"\n",
      "  # MLproject file has to have main entry_point. It can be toggled without using -e option.\n",
      "  main:\n",
      "    # parameters is a key-value collection.\n",
      "    parameters:\n",
      "      file_name:\n",
      "        type: str\n",
      "        default: \"wine.csv\"\n",
      "      max_k:\n",
      "        type: int\n",
      "        default: 10\n",
      "    command: \"python train_new.py {file_name} {max_k}\""
     ]
    }
   ],
   "source": [
    "%cat MLproject\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/04 15:33:27 INFO mlflow.utils.conda: Conda environment mlflow-06da0cf272d5df6bef864f6179e2bdc8b537d6de already exists.\n",
      "2023/05/04 15:33:27 INFO mlflow.projects.utils: === Created directory /tmp/tmptcwvv5zz for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2023/05/04 15:33:27 INFO mlflow.projects.backend.local: === Running command 'source /home/muhammadsafi/anaconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-06da0cf272d5df6bef864f6179e2bdc8b537d6de 1>&2 && python train_new.py wine.csv 10' in run with ID '83d8832f36fb4338b8310c2fe3c3213f' === \n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 15:33:31 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 46\n",
      "Created version '46' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 15:33:32 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 47\n",
      "Created version '47' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 15:33:33 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 48\n",
      "Created version '48' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 15:33:35 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 49\n",
      "Created version '49' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 15:33:36 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 50\n",
      "Created version '50' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 15:33:37 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 51\n",
      "Created version '51' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 15:33:39 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 52\n",
      "Created version '52' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 15:33:40 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 53\n",
      "Created version '53' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 15:33:41 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 54\n",
      "Created version '54' of model 'sklearn_classification_assignment'.\n",
      "2023/05/04 15:33:42 INFO mlflow.projects: === Run (ID '83d8832f36fb4338b8310c2fe3c3213f') succeeded ===\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source mlflow_env_vars.sh\n",
    "mlflow run . \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Stored Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact_path: logisticRegression\n",
      "flavors:\n",
      "  python_function:\n",
      "    env:\n",
      "      conda: conda.yaml\n",
      "      virtualenv: python_env.yaml\n",
      "    loader_module: mlflow.sklearn\n",
      "    model_path: model.pkl\n",
      "    predict_fn: predict\n",
      "    python_version: 3.11.3\n",
      "  sklearn:\n",
      "    code: null\n",
      "    pickled_model: model.pkl\n",
      "    serialization_format: cloudpickle\n",
      "    sklearn_version: 1.2.2\n",
      "mlflow_version: 2.3.1\n",
      "model_uuid: 580eda138f6d4f12ba095fcff6675cf7\n",
      "run_id: fd9d89334cd1405e89049a5a6f35c761\n",
      "utc_time_created: '2023-05-04 05:52:58.030219'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "last_model_path=$(ls -tr mlruns/0/ | tail -1)\n",
    "cat mlruns/0/$last_model_path/artifacts/logisticRegression/MLmodel\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serving model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "source mlflow_env_vars.sh\n",
    "mlflow --version\n",
    "mlflow models serve -m models:/sklearn_classification_assignment/Production -p 5001 --env-manager=conda "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture\n",
      "0        17.99         10.38\n",
      "1        20.57         17.77\n",
      "2        19.69         21.25\n",
      "3        11.42         20.38\n",
      "4        20.29         14.34\n"
     ]
    }
   ],
   "source": [
    "cancer_df=datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data=cancer_df.data, columns=cancer_df.feature_names)\n",
    "print(df.iloc[:,:2].head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17.99, 10.38], [20.57, 17.77], [19.69, 21.25], [11.42, 20.38], [20.29, 14.34], [12.45, 15.7], [18.25, 19.98], [13.71, 20.83], [13.0, 21.82], [12.46, 24.04], [16.02, 23.24], [15.78, 17.89], [19.17, 24.8], [15.85, 23.95], [13.73, 22.61], [14.54, 27.54], [14.68, 20.13], [16.13, 20.68], [19.81, 22.15], [13.54, 14.36], [13.08, 15.71], [9.504, 12.44], [15.34, 14.26], [21.16, 23.04], [16.65, 21.38], [17.14, 16.4], [14.58, 21.53], [18.61, 20.25], [15.3, 25.27], [17.57, 15.05], [18.63, 25.11], [11.84, 18.7]] check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   631  100   113  100   518  24737   110k --:--:-- --:--:-- --:--:--  154k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "data='[[17.99, 10.38], [20.57, 17.77], [19.69, 21.25], [11.42, 20.38], [20.29, 14.34], [12.45, 15.7], [18.25, 19.98], [13.71, 20.83], [13.0, 21.82], [12.46, 24.04], [16.02, 23.24], [15.78, 17.89], [19.17, 24.8], [15.85, 23.95], [13.73, 22.61], [14.54, 27.54], [14.68, 20.13], [16.13, 20.68], [19.81, 22.15], [13.54, 14.36], [13.08, 15.71], [9.504, 12.44], [15.34, 14.26], [21.16, 23.04], [16.65, 21.38], [17.14, 16.4], [14.58, 21.53], [18.61, 20.25], [15.3, 25.27], [17.57, 15.05], [18.63, 25.11], [11.84, 18.7]]'\n",
    "echo $data \"check\"\n",
    "\n",
    "curl -d \"{\\\"inputs\\\": $data}\" -H 'Content-Type: application/json' 127.0.0.1:5001/invocations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17.99, 10.38], [20.57, 17.77], [19.69, 21.25], [11.42, 20.38], [20.29, 14.34], [12.45, 15.7], [18.25, 19.98], [13.71, 20.83], [13.0, 21.82], [12.46, 24.04], [16.02, 23.24], [15.78, 17.89], [19.17, 24.8], [15.85, 23.95], [13.73, 22.61], [14.54, 27.54], [14.68, 20.13], [16.13, 20.68], [19.81, 22.15], [13.54, 14.36], [13.08, 15.71], [9.504, 12.44], [15.34, 14.26], [21.16, 23.04], [16.65, 21.38], [17.14, 16.4], [14.58, 21.53], [18.61, 20.25], [15.3, 25.27], [17.57, 15.05], [18.63, 25.11], [11.84, 18.7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   634  100   113  100   521  62638   282k --:--:-- --:--:-- --:--:--  619k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "data='[[17.99, 10.38], [20.57, 17.77], [19.69, 21.25], [11.42, 20.38], [20.29, 14.34], [12.45, 15.7], [18.25, 19.98], [13.71, 20.83], [13.0, 21.82], [12.46, 24.04], [16.02, 23.24], [15.78, 17.89], [19.17, 24.8], [15.85, 23.95], [13.73, 22.61], [14.54, 27.54], [14.68, 20.13], [16.13, 20.68], [19.81, 22.15], [13.54, 14.36], [13.08, 15.71], [9.504, 12.44], [15.34, 14.26], [21.16, 23.04], [16.65, 21.38], [17.14, 16.4], [14.58, 21.53], [18.61, 20.25], [15.3, 25.27], [17.57, 15.05], [18.63, 25.11], [11.84, 18.7]]'\n",
    "echo $data\n",
    "\n",
    "curl -d \"{\\\"instances\\\": $data}\" -H 'Content-Type: application/json' 127.0.0.1:5001/invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17.99, 10.38], [20.57, 17.77], [19.69, 21.25], [11.42, 20.38], [20.29, 14.34], [12.45, 15.7], [18.25, 19.98], [13.71, 20.83], [13.0, 21.82], [12.46, 24.04], [16.02, 23.24], [15.78, 17.89], [19.17, 24.8], [15.85, 23.95], [13.73, 22.61], [14.54, 27.54], [14.68, 20.13], [16.13, 20.68], [19.81, 22.15], [13.54, 14.36], [13.08, 15.71], [9.504, 12.44], [15.34, 14.26], [21.16, 23.04], [16.65, 21.38], [17.14, 16.4], [14.58, 21.53], [18.61, 20.25], [15.3, 25.27], [17.57, 15.05], [18.63, 25.11], [11.84, 18.7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "/home/muhammadsafi/Desktop/assignment_repo/tasks/mlops-assignment/lib/python3.10/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "100   677  100   113  100   564  25370   123k --:--:-- --:--:-- --:--:--  165k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "data='[[17.99, 10.38], [20.57, 17.77], [19.69, 21.25], [11.42, 20.38], [20.29, 14.34], [12.45, 15.7], [18.25, 19.98], [13.71, 20.83], [13.0, 21.82], [12.46, 24.04], [16.02, 23.24], [15.78, 17.89], [19.17, 24.8], [15.85, 23.95], [13.73, 22.61], [14.54, 27.54], [14.68, 20.13], [16.13, 20.68], [19.81, 22.15], [13.54, 14.36], [13.08, 15.71], [9.504, 12.44], [15.34, 14.26], [21.16, 23.04], [16.65, 21.38], [17.14, 16.4], [14.58, 21.53], [18.61, 20.25], [15.3, 25.27], [17.57, 15.05], [18.63, 25.11], [11.84, 18.7]]'\n",
    "columns='[\"temp\",\"casual\"]'\n",
    "echo $data\n",
    "\n",
    "curl -d \"{\\\"dataframe_split\\\":{\\\"columns\\\":[\\\"temp\\\",\\\"casual\\\"],\\\"data\\\": $data}}\" -H 'Content-Type: application/json' 127.0.0.1:5001/invocations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow Dashboard\n",
    "![alternative text](/home/muhammadsafi/Desktop/assignment_repo/tasks/3.4A_assignment/3.4A&B.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alternative text](/home/muhammadsafi/Desktop/assignment_repo/tasks/3.4A_and_3.4B_assignment/3.4A&B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
