{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Muhammad Safi (2303.KHI.DEG.023)\n",
    "\n",
    "Assignment Partner: Huzaifa Ali (2303.KHI.DEG.016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/muhammadsafi/Desktop/assignment_repo/tasks/mlops-assignment/bin/python\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import sys; print(sys.executable)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up MLFlow Tracking Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "\n",
    "mlflow server --host 0.0.0.0 \\\n",
    "    --port 5000 \\\n",
    "    --backend-store-uri sqlite:///mlflow.db \\\n",
    "    --default-artifact-root ./mlruns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: basic_mlflow\n",
      "\n",
      "# this file is used to configure Python package dependencies.\n",
      "# it uses Anaconda, but it can be also alternatively configured to use pip.\n",
      "conda_env: conda.yaml\n",
      "\n",
      "# entry points can be ran using `mlflow run <project_name> -e <entry_point_name>\n",
      "entry_points:\n",
      "  # download_data:\n",
      "  #   # you can run any command using MLFlow\n",
      "  #   command: \"bash download_data.sh\"\n",
      "  # MLproject file has to have main entry_point. It can be toggled without using -e option.\n",
      "  main:\n",
      "    # parameters is a key-value collection.\n",
      "    parameters:\n",
      "      file_name:\n",
      "        type: str\n",
      "        default: \"wine.csv\"\n",
      "      max_k:\n",
      "        type: int\n",
      "        default: 10\n",
      "    command: \"python train_new.py {file_name} {max_k}\""
     ]
    }
   ],
   "source": [
    "%cat MLproject\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/04 14:23:41 INFO mlflow.utils.conda: Conda environment mlflow-06da0cf272d5df6bef864f6179e2bdc8b537d6de already exists.\n",
      "2023/05/04 14:23:41 INFO mlflow.projects.utils: === Created directory /tmp/tmpwrb8wgb_ for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2023/05/04 14:23:41 INFO mlflow.projects.backend.local: === Running command 'source /home/muhammadsafi/anaconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-06da0cf272d5df6bef864f6179e2bdc8b537d6de 1>&2 && python train_new.py wine.csv 10' in run with ID 'ac0c582216184913ade70683a7f49935' === \n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 14:23:45 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 37\n",
      "Created version '37' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 14:23:46 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 38\n",
      "Created version '38' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 14:23:48 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 39\n",
      "Created version '39' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 14:23:49 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 40\n",
      "Created version '40' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 14:23:50 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 41\n",
      "Created version '41' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 14:23:52 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 42\n",
      "Created version '42' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 14:23:53 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 43\n",
      "Created version '43' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 14:23:54 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 44\n",
      "Created version '44' of model 'sklearn_classification_assignment'.\n",
      "Registered model 'sklearn_classification_assignment' already exists. Creating a new version of this model...\n",
      "2023/05/04 14:23:56 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sklearn_classification_assignment, version 45\n",
      "Created version '45' of model 'sklearn_classification_assignment'.\n",
      "2023/05/04 14:23:56 INFO mlflow.projects: === Run (ID 'ac0c582216184913ade70683a7f49935') succeeded ===\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source mlflow_env_vars.sh\n",
    "mlflow run . \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Stored Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact_path: logisticRegression\n",
      "flavors:\n",
      "  python_function:\n",
      "    env:\n",
      "      conda: conda.yaml\n",
      "      virtualenv: python_env.yaml\n",
      "    loader_module: mlflow.sklearn\n",
      "    model_path: model.pkl\n",
      "    predict_fn: predict\n",
      "    python_version: 3.10.6\n",
      "  sklearn:\n",
      "    code: null\n",
      "    pickled_model: model.pkl\n",
      "    serialization_format: cloudpickle\n",
      "    sklearn_version: 1.2.2\n",
      "mlflow_version: 2.3.1\n",
      "model_uuid: 5996a2bc5db4485981df8ebfc6407ce8\n",
      "run_id: 80a872a13856485685de3b31b94f9c40\n",
      "utc_time_created: '2023-05-04 09:23:54.795330'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "last_model_path=$(ls -tr mlruns/0/ | tail -1)\n",
    "cat mlruns/0/$last_model_path/artifacts/logisticRegression/MLmodel\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serving model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "source mlflow_env_vars.sh\n",
    "mlflow --version\n",
    "mlflow models serve -m models:/sklearn_classification_assignment/Production -p 5002 --env-manager=conda "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture\n",
      "0        17.99         10.38\n",
      "1        20.57         17.77\n",
      "2        19.69         21.25\n",
      "3        11.42         20.38\n",
      "4        20.29         14.34\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "cancer_df=datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data=cancer_df.data, columns=cancer_df.feature_names)\n",
    "print(df.iloc[:,:2].head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17.99, 10.38], [20.57, 17.77], [19.69, 21.25], [11.42, 20.38], [20.29, 14.34], [12.45, 15.7], [18.25, 19.98], [13.71, 20.83], [13.0, 21.82], [12.46, 24.04], [16.02, 23.24], [15.78, 17.89], [19.17, 24.8], [15.85, 23.95], [13.73, 22.61], [14.54, 27.54], [14.68, 20.13], [16.13, 20.68], [19.81, 22.15], [13.54, 14.36], [13.08, 15.71], [9.504, 12.44], [15.34, 14.26], [21.16, 23.04], [16.65, 21.38], [17.14, 16.4], [14.58, 21.53], [18.61, 20.25], [15.3, 25.27], [17.57, 15.05], [18.63, 25.11], [11.84, 18.7]] check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   631  100   113  100   518  34398   153k --:--:-- --:--:-- --:--:--  205k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "data='[[17.99, 10.38], [20.57, 17.77], [19.69, 21.25], [11.42, 20.38], [20.29, 14.34], [12.45, 15.7], [18.25, 19.98], [13.71, 20.83], [13.0, 21.82], [12.46, 24.04], [16.02, 23.24], [15.78, 17.89], [19.17, 24.8], [15.85, 23.95], [13.73, 22.61], [14.54, 27.54], [14.68, 20.13], [16.13, 20.68], [19.81, 22.15], [13.54, 14.36], [13.08, 15.71], [9.504, 12.44], [15.34, 14.26], [21.16, 23.04], [16.65, 21.38], [17.14, 16.4], [14.58, 21.53], [18.61, 20.25], [15.3, 25.27], [17.57, 15.05], [18.63, 25.11], [11.84, 18.7]]'\n",
    "echo $data \"check\"\n",
    "\n",
    "curl -d \"{\\\"inputs\\\": $data}\" -H 'Content-Type: application/json' 127.0.0.1:5001/invocations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17.99, 10.38], [20.57, 17.77], [19.69, 21.25], [11.42, 20.38], [20.29, 14.34], [12.45, 15.7], [18.25, 19.98], [13.71, 20.83], [13.0, 21.82], [12.46, 24.04], [16.02, 23.24], [15.78, 17.89], [19.17, 24.8], [15.85, 23.95], [13.73, 22.61], [14.54, 27.54], [14.68, 20.13], [16.13, 20.68], [19.81, 22.15], [13.54, 14.36], [13.08, 15.71], [9.504, 12.44], [15.34, 14.26], [21.16, 23.04], [16.65, 21.38], [17.14, 16.4], [14.58, 21.53], [18.61, 20.25], [15.3, 25.27], [17.57, 15.05], [18.63, 25.11], [11.84, 18.7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   634  100   113  100   521  56898   256k --:--:-- --:--:-- --:--:--  619k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "data='[[17.99, 10.38], [20.57, 17.77], [19.69, 21.25], [11.42, 20.38], [20.29, 14.34], [12.45, 15.7], [18.25, 19.98], [13.71, 20.83], [13.0, 21.82], [12.46, 24.04], [16.02, 23.24], [15.78, 17.89], [19.17, 24.8], [15.85, 23.95], [13.73, 22.61], [14.54, 27.54], [14.68, 20.13], [16.13, 20.68], [19.81, 22.15], [13.54, 14.36], [13.08, 15.71], [9.504, 12.44], [15.34, 14.26], [21.16, 23.04], [16.65, 21.38], [17.14, 16.4], [14.58, 21.53], [18.61, 20.25], [15.3, 25.27], [17.57, 15.05], [18.63, 25.11], [11.84, 18.7]]'\n",
    "echo $data\n",
    "\n",
    "curl -d \"{\\\"instances\\\": $data}\" -H 'Content-Type: application/json' 127.0.0.1:5001/invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17.99, 10.38], [20.57, 17.77], [19.69, 21.25], [11.42, 20.38], [20.29, 14.34], [12.45, 15.7], [18.25, 19.98], [13.71, 20.83], [13.0, 21.82], [12.46, 24.04], [16.02, 23.24], [15.78, 17.89], [19.17, 24.8], [15.85, 23.95], [13.73, 22.61], [14.54, 27.54], [14.68, 20.13], [16.13, 20.68], [19.81, 22.15], [13.54, 14.36], [13.08, 15.71], [9.504, 12.44], [15.34, 14.26], [21.16, 23.04], [16.65, 21.38], [17.14, 16.4], [14.58, 21.53], [18.61, 20.25], [15.3, 25.27], [17.57, 15.05], [18.63, 25.11], [11.84, 18.7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   677  100   113  100   564  17541  87550 --:--:-- --:--:-- --:--:--  110k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]}"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "data='[[17.99, 10.38], [20.57, 17.77], [19.69, 21.25], [11.42, 20.38], [20.29, 14.34], [12.45, 15.7], [18.25, 19.98], [13.71, 20.83], [13.0, 21.82], [12.46, 24.04], [16.02, 23.24], [15.78, 17.89], [19.17, 24.8], [15.85, 23.95], [13.73, 22.61], [14.54, 27.54], [14.68, 20.13], [16.13, 20.68], [19.81, 22.15], [13.54, 14.36], [13.08, 15.71], [9.504, 12.44], [15.34, 14.26], [21.16, 23.04], [16.65, 21.38], [17.14, 16.4], [14.58, 21.53], [18.61, 20.25], [15.3, 25.27], [17.57, 15.05], [18.63, 25.11], [11.84, 18.7]]'\n",
    "columns='[\"temp\",\"casual\"]'\n",
    "echo $data\n",
    "\n",
    "curl -d \"{\\\"dataframe_split\\\":{\\\"columns\\\":[\\\"temp\\\",\\\"casual\\\"],\\\"data\\\": $data}}\" -H 'Content-Type: application/json' 127.0.0.1:5001/invocations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow Dashboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alternative text](/home/muhammadsafi/Desktop/assignment_repo/tasks/3.4A_and_3.4B_assignment/3.4A&B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
